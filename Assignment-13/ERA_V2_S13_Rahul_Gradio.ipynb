{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyPqFEoDIvyWSpicu61+zuiO",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Himank-J/ERAV2/blob/main/S13/ERAV2_S13_Himank_Gradio.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import sys\n",
        "sys.path.append(\".\")"
      ],
      "metadata": {
        "id": "gIKnTbKK0RWp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-NceE6B6zKV8"
      },
      "outputs": [],
      "source": [
        "import torch, torchvision\n",
        "from torchvision import transforms\n",
        "import numpy as np\n",
        "import gradio as gr\n",
        "from PIL import Image\n",
        "from pytorch_grad_cam import GradCAM\n",
        "from pytorch_grad_cam.utils.image import show_cam_on_image\n",
        "from model import ResNet18"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model = ResNet18()\n",
        "model.load_state_dict(torch.load(\"model.pth\", map_location=torch.device('cpu')), strict=False)\n",
        "\n",
        "inv_normalize = transforms.Normalize(\n",
        "    mean=[-0.50/0.23, -0.50/0.23, -0.50/0.23],\n",
        "    std=[1/0.23, 1/0.23, 1/0.23]\n",
        ")\n",
        "classes = ('plane', 'car', 'bird', 'cat', 'deer',\n",
        "           'dog', 'frog', 'horse', 'ship', 'truck')"
      ],
      "metadata": {
        "id": "iMiaXlWY0c3c"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def resize_image_pil(image, new_width, new_height):\n",
        "\n",
        "    img = Image.fromarray(np.array(image))\n",
        "    width, height = img.size\n",
        "\n",
        "    width_scale = new_width / width\n",
        "    height_scale = new_height / height\n",
        "    scale = min(width_scale, height_scale)\n",
        "    resized = img.resize((int(width*scale), int(height*scale)), Image.NEAREST)\n",
        "    resized = resized.crop((0, 0, new_width, new_height))\n",
        "\n",
        "    return resized"
      ],
      "metadata": {
        "id": "5lFEJRot0VUr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def inference(input_img,enable_grad_cam,transparency=0.5,target_layer_number=-1,num_top_classes=2):\n",
        "    input_img = resize_image_pil(input_img, 32, 32)\n",
        "\n",
        "    input_img = np.array(input_img)\n",
        "    org_img = input_img\n",
        "    input_img = input_img.reshape((32, 32, 3))\n",
        "    transform = transforms.ToTensor()\n",
        "    input_img = transform(input_img)\n",
        "    input_img = input_img\n",
        "    input_img = input_img.unsqueeze(0)\n",
        "    outputs = model(input_img)\n",
        "    softmax = torch.nn.Softmax(dim=0)\n",
        "    o = softmax(outputs.flatten())\n",
        "    confidences = {classes[i]: float(o[i]) for i in range(10)}\n",
        "    _, prediction = torch.max(outputs, 1)\n",
        "    target_layers = [model.layer2[target_layer_number]]\n",
        "    cam = GradCAM(model=model, target_layers=target_layers)\n",
        "    grayscale_cam = cam(input_tensor=input_img, targets=None)\n",
        "    grayscale_cam = grayscale_cam[0, :]\n",
        "    img = input_img.squeeze(0)\n",
        "    img = inv_normalize(img)\n",
        "    if enable_grad_cam:\n",
        "      visualization = show_cam_on_image(org_img/255, grayscale_cam, use_rgb=True, image_weight=transparency)\n",
        "    else:\n",
        "      visualization = None\n",
        "\n",
        "    confidences = sorted(confidences.items(), key=lambda x: x[1], reverse=True)\n",
        "    return classes[prediction[0].item()], visualization, dict(confidences[:num_top_classes])\n",
        "\n",
        "title = \"CIFAR10 trained on ResNet18 Model with GradCAM\"\n",
        "description = \"A simple Gradio interface to infer on ResNet model, and get GradCAM results\"\n",
        "examples = [\n",
        "    [\"cat.jpg\", True, 0.5, -1, 2], [\"dog.jpg\", True, 0.5, -1, 3], [\"bird.jpg\", True, 0.5, -1, 4], [\"car.jpg\", False, 0.5, -1, 5], [\"deer.jpg\", True, 0.5, -1, 6],\n",
        "    [\"frog.jpg\", False, 0.5, -1, 7], [\"horse.jpg\", False, 0.45, -1, 8], [\"plane.jpg\", True, 0.30, -2, 9], [\"ship.jpg\", False, 0.25, -2, 10], [\"truck.jpg\", True ,0.75, -2, 1]\n",
        "]\n",
        "demo = gr.Interface(\n",
        "    inference,\n",
        "    inputs = [\n",
        "        gr.Image(width=256, height=256, label=\"Input Image\"),\n",
        "        gr.Checkbox(value=False, label=\"Enable grad-cam image\"),\n",
        "        gr.Slider(0, 1, value = 0.5, label=\"Overall Opacity of Image\"),\n",
        "        gr.Slider(-2, -1, value = -2, step=1, label=\"Select Layer\"),\n",
        "        gr.Number(value=2, label=\"Number of Top Classes to Show\", minimum=1, maximum=10),\n",
        "    ],\n",
        "    outputs = [\n",
        "        gr.Textbox(label=\"Predicted Category\"),\n",
        "        gr.Image(width=256, height=256, label=\"Output\"),\n",
        "        gr.Label()\n",
        "    ],\n",
        "    title = title,\n",
        "    description = description,\n",
        "    examples = examples,\n",
        ")\n",
        "demo.launch()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 680
        },
        "id": "xG6JrAsS2l57",
        "outputId": "461a9237-7ff0-4c9b-d1f2-ef414a494696"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Setting queue=True in a Colab notebook requires sharing enabled. Setting `share=True` (you can turn this off by setting `share=False` in `launch()` explicitly).\n",
            "\n",
            "Colab notebook detected. This cell will run indefinitely so that you can see errors and logs. To turn off, set debug=False in launch().\n",
            "Running on public URL: https://e7a3e358d2fb2a5287.gradio.live\n",
            "\n",
            "This share link expires in 72 hours. For free permanent hosting and GPU upgrades, run `gradio deploy` from Terminal to deploy to Spaces (https://huggingface.co/spaces)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<div><iframe src=\"https://e7a3e358d2fb2a5287.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Keyboard interruption in main thread... closing server.\n",
            "Killing tunnel 127.0.0.1:7869 <> https://e7a3e358d2fb2a5287.gradio.live\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": []
          },
          "metadata": {},
          "execution_count": 22
        }
      ]
    }
  ]
}